{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pyspark in c:\\users\\hp\\anaconda3\\lib\\site-packages (3.5.1)\n",
      "Requirement already satisfied: py4j==0.10.9.7 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from pyspark) (0.10.9.7)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install pyspark\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = SparkSession.builder.appName(\"Practice\").getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pyspark = spark.read.csv('basic_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+---+\n",
      "|    _c0|_c1|\n",
      "+-------+---+\n",
      "|   NAME|AGE|\n",
      "| Swapil| 27|\n",
      "|Neelesh| 28|\n",
      "|  Sukhi| 27|\n",
      "+-------+---+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_pyspark.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pyspark = spark.read.option('header','true').csv('basic_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+---+\n",
      "|   NAME|AGE|\n",
      "+-------+---+\n",
      "| Swapil| 27|\n",
      "|Neelesh| 28|\n",
      "|  Sukhi| 27|\n",
      "+-------+---+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_pyspark.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Row(NAME='Swapil', AGE='27')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_pyspark.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- NAME: string (nullable = true)\n",
      " |-- AGE: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_pyspark.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# READ DATASET 2\n",
    "df_pyspark = spark.read.option('header','true').csv('basic_data.csv',inferSchema = 'True')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- NAME: string (nullable = true)\n",
      " |-- AGE: integer (nullable = true)\n",
      " |-- EXPERIENCE: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_pyspark.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+---+----------+\n",
      "|   NAME|AGE|EXPERIENCE|\n",
      "+-------+---+----------+\n",
      "| Swapil| 27|         1|\n",
      "|Neelesh| 28|         2|\n",
      "|  Sukhi| 27|         3|\n",
      "+-------+---+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_pyspark = spark.read.csv('basic_data.csv', header=True, inferSchema=True)\n",
    "df_pyspark.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(NAME='Swapil', AGE=27, EXPERIENCE=1),\n",
       " Row(NAME='Neelesh', AGE=28, EXPERIENCE=2),\n",
       " Row(NAME='Sukhi', AGE=27, EXPERIENCE=3)]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_pyspark.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+----------+\n",
      "|   Name|Experience|\n",
      "+-------+----------+\n",
      "| Swapil|         1|\n",
      "|Neelesh|         2|\n",
      "|  Sukhi|         3|\n",
      "+-------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# selecting and showing columns\n",
    "df_pyspark.select(['Name','Experience']).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('NAME', 'string'), ('AGE', 'int'), ('EXPERIENCE', 'int')]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# data types\n",
    "df_pyspark.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-------+------------------+----------+\n",
      "|summary|   NAME|               AGE|EXPERIENCE|\n",
      "+-------+-------+------------------+----------+\n",
      "|  count|      3|                 3|         3|\n",
      "|   mean|   NULL|27.333333333333332|       2.0|\n",
      "| stddev|   NULL|0.5773502691896258|       1.0|\n",
      "|    min|Neelesh|                27|         1|\n",
      "|    max| Swapil|                28|         3|\n",
      "+-------+-------+------------------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_pyspark.describe().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-------+------------------+----------+-----------------------+\n",
      "|summary|   NAME|               AGE|EXPERIENCE|Experience after 2 year|\n",
      "+-------+-------+------------------+----------+-----------------------+\n",
      "|  count|      3|                 3|         3|                      3|\n",
      "|   mean|   NULL|27.333333333333332|       2.0|                    4.0|\n",
      "| stddev|   NULL|0.5773502691896258|       1.0|                    1.0|\n",
      "|    min|Neelesh|                27|         1|                      3|\n",
      "|    max| Swapil|                28|         3|                      5|\n",
      "+-------+-------+------------------+----------+-----------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# adding column in dataframe\n",
    "df_pyspark2 = df_pyspark.withColumn('Experience after 2 year', df_pyspark['Experience']+2)\n",
    "df_pyspark2.describe().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
